{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaoc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import ast\n",
    "from pandas import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "should work for any report type as long as it's formatted properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_cols = ['SourcePDF', 'Comments', 'DocType', 'ExamDate', 'Device', 'ID', 'Race', 'Occupation', 'Technician', 'RecordingType']\n",
    "\n",
    "def analyze_data(df):\n",
    "    df = df.replace('---', pd.NaT)\n",
    "    fix_data_types(df)\n",
    "    handle_missing_values(df)\n",
    "    display_graphs(df)\n",
    "\n",
    "def fix_data_types(df):\n",
    "    df['ExamDate'] = pd.to_datetime(df['ExamDate'], format='%d-%m-%Y')\n",
    "    \n",
    "    #convert all columns to numeric (excecpt ['SourcePDF', 'Notes', 'DocType', 'ExamDate'])\n",
    "    for col in df.columns:\n",
    "        if col not in nominal_cols:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "\n",
    "def handle_missing_values(df):\n",
    "\n",
    "    #missing_values = df.isnull().sum()\n",
    "    #print(missing_values)\n",
    "\n",
    "    #all body position stats columns have missing values replace with 0 (no events or time spent in that position)\n",
    "    for col in df.columns:\n",
    "        if 'Position' in col:\n",
    "            df[col] = df[col].fillna(0)\n",
    "\n",
    "    #for now we'll replace missing values with the mean, futurely maybe we can try imputing with a model (though we dont have a lot of data rn)\n",
    "    for col in df.columns:\n",
    "        if col not in nominal_cols:\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "    #! NOTE: patient measurements (height, weight, age) are always missing on short reports, as such we wont be able to use them for analysis for now.\n",
    "\n",
    "\n",
    "def univariate_analysis(df, column_name):\n",
    "    if column_name not in df.columns:\n",
    "        return f\"Column {column_name} not found in DataFrame.\"\n",
    "    \n",
    "    if df[column_name].dtype not in ['int64', 'float64', 'int32', 'float32']:\n",
    "        return f\"Column {column_name} is not numeric.\"\n",
    "    \n",
    "    data = df[column_name]\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean_val = data.mean()\n",
    "    median_val = data.median()\n",
    "    min_val = data.min()\n",
    "    max_val = data.max()\n",
    "    kurtosis_val = data.kurtosis()\n",
    "    skewness_val = data.skew()\n",
    "    std_dev = data.std()\n",
    "    variance = data.var()\n",
    "\n",
    "    print(f\"Mean: {mean_val}\")\n",
    "    print(f\"Median: {median_val}\")\n",
    "    print(f\"Min: {min_val}\")\n",
    "    print(f\"Max: {max_val}\")\n",
    "    print(f\"Kurtosis: {kurtosis_val}\")\n",
    "    print(f\"Skewness: {skewness_val}\")\n",
    "    print(f\"Standard Deviation: {std_dev}\")\n",
    "    print(f\"Variance: {variance}\")\n",
    "\n",
    "    return {\n",
    "        'Mean': mean_val,\n",
    "        'Median': median_val,\n",
    "        'Min': min_val,\n",
    "        'Max': max_val,\n",
    "        'Kurtosis': kurtosis_val,\n",
    "        'Skewness': skewness_val,\n",
    "        'Standard Deviation': std_dev,\n",
    "        'Variance': variance\n",
    "    }\n",
    "\n",
    "def bivariate_analysis(df, column_name1, column_name2):\n",
    "\n",
    "    #scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=df, x=df[column_name1], y=df[column_name2])\n",
    "    plt.title(f\"Scatter plot {column_name1} vs {column_name2}\")\n",
    "    plt.xlabel(column_name1)\n",
    "    plt.ylabel(column_name2)\n",
    "    plt.show()\n",
    "\n",
    "    #correlation\n",
    "    pearson_corr, pearson_p = stats.pearsonr(df[column_name1], df[column_name2])\n",
    "    spearman_corr, spearman_p = stats.spearmanr(df[column_name1], df[column_name2])\n",
    "\n",
    "    print(f\"Pearson correlation between {column_name1} and {column_name2}: r = {pearson_corr}, p = {pearson_p}\")\n",
    "    print(f\"Spearman correlation between {column_name1} and {column_name2}: r = {spearman_corr}, p = {spearman_p}\")\n",
    "\n",
    "    sns.jointplot(data=df, x=column_name1, y=column_name2, kind='reg')\n",
    "    plt.show()\n",
    "\n",
    "    #Box plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=df[column_name1], y=df[column_name2])\n",
    "    plt.title(f\"Box plot {column_name1} vs {column_name2}\")\n",
    "    plt.xlabel(column_name1)\n",
    "    plt.ylabel(column_name2)\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        'Pearson Correlation': pearson_corr,\n",
    "        'Pearson P-value': pearson_p,\n",
    "        'Spearman Correlation': spearman_corr,\n",
    "        'Spearman P-value': spearman_p\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "def display_graphs(df):\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "    #plot histograms for all numeric columns\n",
    "    for col in numeric_cols:\n",
    "        plt.figure()\n",
    "        sns.histplot(df[col])\n",
    "        plt.title(col)\n",
    "        plt.show\n",
    "\n",
    "    #plot correlation matrix\n",
    "    corr = df[numeric_cols].corr()\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".1f\")\n",
    "    plt.show()\n",
    "\n",
    "    #plot scatter plots for all columns\n",
    "    for col in numeric_cols:\n",
    "        \n",
    "        plt.figure()\n",
    "        sns.scatterplot(data=df, x=col, y='SleepEfficiency')\n",
    "        plt.title(col)\n",
    "        plt.show()\n",
    "\n",
    "def medi_albertina_comment_analysis(df):\n",
    "    ner_pipeline = pipeline('ner', model='portugueseNLP/medialbertina_pt-pt_900m_NER', aggregation_strategy='average')\n",
    "\n",
    "    # Extract entities from all \"Comments\", store them in dictionary with SourcePDF as key for each comment.\n",
    "    # Remove all results with tag \"resultado\" as they are not relevant for this analysis\n",
    "    entities = {}\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['Comments'] != pd.NaT:\n",
    "            entities[row['SourcePDF']] = ner_pipeline(row['Comments'])\n",
    "            entities[row['SourcePDF']] = [entity for entity in entities[row['SourcePDF']] if entity['entity_group'] != 'Resultado']\n",
    "\n",
    "            # Convert scores to string for serialization\n",
    "            for entity in entities[row['SourcePDF']]:\n",
    "                entity['score'] = str(entity['score'])\n",
    "                entity['start'] = str(entity['start'])\n",
    "                entity['end'] = str(entity['end'])\n",
    "\n",
    "            print(f\"Extracted entities from {row['SourcePDF']}\")\n",
    "            print(entities[row['SourcePDF']])\n",
    "\n",
    "    with open('entities.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(entities, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    return entities\n",
    "\n",
    "#! NOT FULLY IMPLEMENTED\n",
    "def bioBERTpt_comment_analysis(text):\n",
    "\n",
    "    ner_pipeline = pipeline(\"ner\", model=\"pucpr/biobertpt-all\", tokenizer=\"pucpr/biobertpt-all\")\n",
    "\n",
    "    ner_results = ner_pipeline(text)\n",
    "\n",
    "    for entity in ner_results:\n",
    "        print(f\"Entity: {entity['word']}, Label: {entity['entity']}, Confidence: {entity['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### short report notes\n",
    "\n",
    "Although there is a clear lack of data, we can make some assumptions and reach conclusions based on whats available,\n",
    "1- the biggest factors contributing to sleep efficiency are the number the total time slept, and total time in rem and nrem\n",
    "2- apneas and hypopneas seem to have a negative effect on sleep efficiency (as expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REM LOGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/csvs/report_summary.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/csvs/RemLogicData.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SnoreDuration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('---', pd.NaT)\n",
    "fix_data_types(df)\n",
    "handle_missing_values(df)\n",
    "df['Type']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the Data Common In Both RemLogic Reports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_common_data(df):\n",
    "    #Clean Total Time Data\n",
    "    df['total_recording_time'] = df['total_recording_time'].str.replace(' minutes', '').astype(int)\n",
    "\n",
    "    #Clean Age Data\n",
    "    cleaned_list = []\n",
    "    for entry in df['age']:\n",
    "        entry = entry.strip()  # Remove leading/trailing whitespace\n",
    "        if entry == '- month(s)' or ' month(s)' in entry:\n",
    "            cleaned_list.append(None)\n",
    "        else:\n",
    "            cleaned_list.append(int(entry.split(' year(s)')[0]))\n",
    "\n",
    "    # Calculate mean of non-None values\n",
    "    filtered_data = [x for x in cleaned_list if x is not None]\n",
    "    mean_value = int(sum(filtered_data) / len(filtered_data))\n",
    "\n",
    "    # Replace None with mean\n",
    "    for i in range(len(cleaned_list)):\n",
    "        if cleaned_list[i] is None:\n",
    "            cleaned_list[i] = mean_value\n",
    "\n",
    "    df['age'] = cleaned_list \n",
    "\n",
    "    #Clean Height Data\n",
    "    df['height'] = df['height'].replace(\"NaN\", np.nan)\n",
    "    df['height'] = df['height'].str.replace(' m', '').str.replace(',', '.').astype(float)\n",
    "    df['height'] = df['height'].fillna(df['height'].mean())\n",
    "\n",
    "    #Clean Weight Data\n",
    "    df['weight'] = df['weight'].replace(\"NaN\", np.nan)\n",
    "    df['weight'] = df['weight'].str.replace(' kg', '').str.replace(',', '.').astype(float)\n",
    "    df['weight'] = df['weight'].fillna(df['weight'].mean())\n",
    "\n",
    "    #Clean Apnea + Hypopnea (A+H) Data\n",
    "    apnea_hypopnea_count = df['Apnea + Hypopnea (A+H)'].str.split(' ', n=1).str[0].astype(int)\n",
    "    rate = df['Apnea + Hypopnea (A+H)'].str.split(' ', n=1).str[1].str.replace(' / h', '')\n",
    "    apnea_hypopnea_rate = rate.str.replace(',', '.').astype(float)\n",
    "    df['Apnea + Hypopnea (A+H) Rate'] = apnea_hypopnea_rate\n",
    "\n",
    "    #Clean Snore Time Data\n",
    "    lst = []\n",
    "    for i in df['Snore Time']:\n",
    "        if i == '- - %':\n",
    "            lst.append('0 minutes 0 %')\n",
    "        else:\n",
    "            lst.append(i)\n",
    "\n",
    "    df['Snore Time'] = lst\n",
    "    saturation_count = df['Snore Time'].str.split(' minutes', n=1).str[0].str.replace(',', '.').astype(float)\n",
    "    saturation_rate = df['Snore Time'].str.split(' minutes', n=1).str[1].str.replace('%', '').str.replace(',', '.').astype(float)\n",
    "    df['Snore Time'] = saturation_count\n",
    "\n",
    "    #Clean Lowest Oxygen Saturation Data\n",
    "    df['Lowest Oxygen Saturation'] = df['Lowest Oxygen Saturation'].str.replace(' %', '')\n",
    "    df['Lowest Oxygen Saturation'] = df['Lowest Oxygen Saturation'].str.replace(',', '.').astype(float)\n",
    "\n",
    "    #Clean Saturation < 90% Data\n",
    "    lst = []\n",
    "    for i in df['Saturation < 90%']:\n",
    "        if i == '- - %':\n",
    "            lst.append('0 minutes 0 %')\n",
    "        else:\n",
    "            lst.append(i)\n",
    "\n",
    "    df['Saturation < 90%'] = lst\n",
    "    saturation_count = df['Saturation < 90%'].str.split(' minutes', n=1).str[0].str.replace(',', '.').astype(float)\n",
    "    saturation_rate = df['Saturation < 90%'].str.split(' minutes', n=1).str[1].str.replace('%', '').str.replace(',', '.').astype(float)\n",
    "    df['Saturation < 90% Rate'] = saturation_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the Data From **Polysomnography** Report RemLogic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_Polysomnography(df):\n",
    "    #Clean Sleep Efficiency Data\n",
    "    df['Sleep Efficiency'] = df['Sleep Efficiency'].str.replace(' %', '')\n",
    "    df['Sleep Efficiency'] = df['Sleep Efficiency'].str.replace(',', '.').astype(float)\n",
    "\n",
    "    #Clean Relative Snoring Time Data\n",
    "    df['Relative Snoring Time'] = df['Relative Snoring Time'].str.replace(' %', '')\n",
    "    df['Relative Snoring Time'] = df['Relative Snoring Time'].str.replace(',', '.').astype(float)\n",
    "\n",
    "    #Clean Number of Snoring Episodes Data\n",
    "    df['Number of Snoring Episodes'] = df['Number of Snoring Episodes'].astype(int)\n",
    "\n",
    "    #Clean Obstructive Apnea Data\n",
    "    obstructive_apnea_count = df['Obstructive Apnea'].str.split(' ', n=1).str[0].astype(int)\n",
    "    rate = df['Obstructive Apnea'].str.split(' ', n=1).str[1].str.replace(' / h', '')\n",
    "    obstructive_apnea_rate = rate.str.replace(',', '.').astype(float)\n",
    "    #df['Obstructive Apnea Count'] = apnea_hypopnea_count\n",
    "    df['Obstructive Apnea Rate'] = obstructive_apnea_rate\n",
    "\n",
    "    #Clean Central Apnea Data\n",
    "    central_apnea_count = df['Central Apnea'].str.split(' ', n=1).str[0].astype(int)\n",
    "    rate = df['Central Apnea'].str.split(' ', n=1).str[1].str.replace(' / h', '')\n",
    "    central_apnea_rate = rate.str.replace(',', '.').astype(float)\n",
    "    #df['Obstructive Apnea Count'] = apnea_hypopnea_count\n",
    "    df['Central Apnea Rate'] = central_apnea_rate\n",
    "\n",
    "    #Clean Mixed Apnea Data\n",
    "    mixed_apnea_count = df['Mixed Apnea'].str.split(' ', n=1).str[0].astype(int)\n",
    "    rate = df['Mixed Apnea'].str.split(' ', n=1).str[1].str.replace(' / h', '')\n",
    "    mixed_apnea_rate = rate.str.replace(',', '.').astype(float)\n",
    "    #df['Obstructive Apnea Count'] = mixed_apnea_count\n",
    "    df['Mixed Apnea Rate'] = mixed_apnea_rate\n",
    "\n",
    "    #Clean Hypopnea (All) Data\n",
    "    hypopnea_count = df['Hypopnea (All)'].str.split(' ', n=1).str[0].astype(int)\n",
    "    rate = df['Hypopnea (All)'].str.split(' ', n=1).str[1].str.replace(' / h', '')\n",
    "    hypopnea_rate = rate.str.replace(',', '.').astype(float)\n",
    "    #df['Hypopnea (All) Count'] = mixed_apnea_count\n",
    "    df['Hypopnea (All) Rate'] = hypopnea_rate\n",
    "\n",
    "    #Clean Obstructive Hypopnea Data\n",
    "    lst = []\n",
    "    for i in df['Obstructive Hypopnea']:\n",
    "        if i == '- -':\n",
    "            lst.append('0 0')\n",
    "        else:\n",
    "            lst.append(i)\n",
    "\n",
    "    df['Obstructive Hypopnea'] = lst\n",
    "    obstructive_hypopnea_count = df['Obstructive Hypopnea'].str.split(' ', n=1).str[0].astype(int)\n",
    "    rate = df['Obstructive Hypopnea'].str.split(' ', n=1).str[1].str.replace(' / h', '')\n",
    "    obstructive_hypopnea_rate = rate.str.replace(',', '.').astype(float)\n",
    "    #df['Hypopnea (All) Count'] = mixed_apnea_count\n",
    "    df['Obstructive Hypopnea Rate'] = obstructive_hypopnea_rate\n",
    "\n",
    "    #Clean Central Hypopnea Data\n",
    "    lst = []\n",
    "    for i in df['Central Hypopnea']:\n",
    "        if i == '- -':\n",
    "            lst.append('0 0')\n",
    "        else:\n",
    "            lst.append(i)\n",
    "\n",
    "    df['Central Hypopnea'] = lst\n",
    "    central_hypopnea_count = df['Central Hypopnea'].str.split(' ', n=1).str[0].astype(int)\n",
    "    rate = df['Central Hypopnea'].str.split(' ', n=1).str[1].str.replace(' / h', '')\n",
    "    central_hypopnea_rate = rate.str.replace(',', '.').astype(float)\n",
    "    #df['Hypopnea (All) Count'] = mixed_apnea_count\n",
    "    df['Central Hypopnea Rate'] = central_hypopnea_rate\n",
    "\n",
    "    #Clean Mixed Hypopnea Data\n",
    "    lst = []\n",
    "    for i in df['Mixed Hypopnea']:\n",
    "        if i == '- -':\n",
    "            lst.append('0 0')\n",
    "        else:\n",
    "            lst.append(i)\n",
    "\n",
    "    df['Mixed Hypopnea'] = lst\n",
    "    mixed_hypopnea_count = df['Mixed Hypopnea'].str.split(' ', n=1).str[0].astype(int)\n",
    "    rate = df['Mixed Hypopnea'].str.split(' ', n=1).str[1].str.replace(' / h', '')\n",
    "    mixed_hypopnea_rate = rate.str.replace(',', '.').astype(float)\n",
    "    #df['Hypopnea (All) Count'] = mixed_apnea_count\n",
    "    df['Mixed Hypopnea Rate'] = mixed_hypopnea_rate\n",
    "\n",
    "    #Clean Apenea Table Data\n",
    "    df['apenea'] = df['apenea'].apply(ast.literal_eval)\n",
    "    df_apnea_expanded = pd.concat([json_normalize(record) for record in df['apenea']], ignore_index=True)\n",
    "    apenea_list = []\n",
    "    obstructive_list = []\n",
    "    central_list = []\n",
    "    mixed_list = []\n",
    "    hypopnea_list = []\n",
    "    obstructive_hypopnea_list = []\n",
    "    central_hypopnea_list = []\n",
    "    mixed_hypopnea_list = []\n",
    "\n",
    "    apenea_list1 = []\n",
    "    obstructive_list1 = []\n",
    "    central_list1 = []\n",
    "    mixed_list1 = []\n",
    "    hypopnea_list1 = []\n",
    "    obstructive_hypopnea_list1 = []\n",
    "    central_hypopnea_list1 = []\n",
    "    mixed_hypopnea_list1 = []\n",
    "\n",
    "    lists_number = [\n",
    "        apenea_list,\n",
    "        obstructive_list,\n",
    "        central_list,\n",
    "        mixed_list,\n",
    "        hypopnea_list,\n",
    "        obstructive_hypopnea_list,\n",
    "        central_hypopnea_list,\n",
    "        mixed_hypopnea_list\n",
    "    ]\n",
    "\n",
    "    lists_AorH = [\n",
    "        apenea_list1,\n",
    "        obstructive_list1,\n",
    "        central_list1,\n",
    "        mixed_list1,\n",
    "        hypopnea_list1,\n",
    "        obstructive_hypopnea_list1,\n",
    "        central_hypopnea_list1,\n",
    "        mixed_hypopnea_list1\n",
    "    ]\n",
    "\n",
    "    for i in range(10):\n",
    "        for j, lst in enumerate(lists_number):\n",
    "            if df['apenea'][i][j]['Number'] == '-':\n",
    "                lst.append(0)\n",
    "            else:\n",
    "                lst.append(int(df['apenea'][i][j]['Number']))\n",
    "\n",
    "    for i in range(10):\n",
    "        for j, lst in enumerate(lists_AorH):\n",
    "            if df['apenea'][i][j]['A or H/h'] == '-':\n",
    "                lst.append(0)\n",
    "            else:\n",
    "                value = df['apenea'][i][j]['A or H/h'].replace(',', '.')\n",
    "                lst.append(float(value))\n",
    "\n",
    "    for i in range(8):\n",
    "        name = f\"apenea_{df['apenea'][0][i]['Respiration']}_Number\"\n",
    "        df[name] = lists_number[i]\n",
    "\n",
    "    for i in range(8):\n",
    "        name = f\"apenea_{df['apenea'][0][i]['Respiration']}_A or H/h\"\n",
    "        df[name] = lists_AorH[i]\n",
    "\n",
    "\n",
    "    #Clean Position Table Data\n",
    "    df['position'] = df['position'].apply(ast.literal_eval)\n",
    "    df_apnea_expanded = pd.concat([json_normalize(record) for record in df['position']], ignore_index=True)\n",
    "    supine_list = []\n",
    "    left_list = []\n",
    "    prone_list = []\n",
    "    right_list = []\n",
    "    upright_list = []\n",
    "    unknown_hypopnea_list = []\n",
    "\n",
    "    supine_list1 = []\n",
    "    left_list1 = []\n",
    "    prone_list1 = []\n",
    "    right_list1 = []\n",
    "    upright_list1 = []\n",
    "    unknown_hypopnea_list1 = []\n",
    "\n",
    "    lists_number = [\n",
    "        supine_list,\n",
    "        left_list,\n",
    "        prone_list,\n",
    "        right_list,\n",
    "        upright_list,\n",
    "        unknown_hypopnea_list\n",
    "    ]\n",
    "\n",
    "    lists_AorH = [\n",
    "        supine_list1,\n",
    "        left_list1,\n",
    "        prone_list1,\n",
    "        right_list1,\n",
    "        upright_list1,\n",
    "        unknown_hypopnea_list1\n",
    "    ]\n",
    "\n",
    "    for i in range(10):\n",
    "        for j, lst in enumerate(lists_number):\n",
    "            if df['position'][i][j]['Index time'] == '-':\n",
    "                lst.append(0)\n",
    "            else:\n",
    "                value = df['position'][i][j]['Index time'].replace(',', '.')\n",
    "                lst.append(float(value))\n",
    "\n",
    "    for i in range(10):\n",
    "        for j, lst in enumerate(lists_AorH):\n",
    "            if df['position'][i][j]['A or H/h'] == '-':\n",
    "                lst.append(0)\n",
    "            else:\n",
    "                value = df['position'][i][j]['A or H/h'].replace(',', '.')\n",
    "                lst.append(float(value))\n",
    "\n",
    "    for i in range(6):\n",
    "        name = f\"position_{df['position'][0][i]['Position']}_Index time\"\n",
    "        df[name] = lists_number[i]\n",
    "\n",
    "    for i in range(6):\n",
    "        name = f\"position_{df['position'][0][i]['Position']}_A or H/h\"\n",
    "        df[name] = lists_AorH[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the Data From **Polygraphy** Report RemLogic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_Polygraphy(df):\n",
    "    #Clean BMI Data\n",
    "    df['BMI'] = df['BMI'].replace(\"NaN\", np.nan)\n",
    "    df['BMI'] = df['BMI'].str.replace(',', '.').astype(float)\n",
    "    df['BMI'] = df['BMI'].fillna(df['BMI'].mean())\n",
    "\n",
    "    #Clean Index Time Data\n",
    "    df['Index Time'] = df['Index Time'].str.replace(' minutes', '').str.replace(',', '.').astype(float)\n",
    "\n",
    "    #Clean Supine A+H Data\n",
    "    apnea_hypopnea_count = df['Supine A+H'].str.split(' ', n=1).str[0].astype(int)\n",
    "    rate = df['Supine A+H'].str.split(' ', n=1).str[1].str.replace(' / h', '')\n",
    "    apnea_hypopnea_rate = rate.str.replace(',', '.').astype(float)\n",
    "    df['Supine A+H Rate'] = apnea_hypopnea_rate\n",
    "\n",
    "    #Clean Non-Supine A+H Data\n",
    "    apnea_hypopnea_count = df['Non-Supine A+H'].str.split(' ', n=1).str[0].astype(int)\n",
    "    rate = df['Non-Supine A+H'].str.split(' ', n=1).str[1].str.replace(' / h', '')\n",
    "    rate = rate.replace('-', '0')\n",
    "    apnea_hypopnea_rate = rate.str.replace(',', '.').astype(float)\n",
    "    df['Non-Supine A+H Rate'] = apnea_hypopnea_rate\n",
    "\n",
    "    #Clean RDI Data\n",
    "    \"\"\"\n",
    "    df['RDI'] = df['RDI'].replace(\"NaN\", np.nan)\n",
    "    df['RDI'] = df['RDI'].str.replace(',', '.').astype(float)\n",
    "    df['RDI'] = df['RDI'].fillna(df['RDI'].mean())\n",
    "    \"\"\"\n",
    "\n",
    "    #Clean Supine Time Data\n",
    "    lst = []\n",
    "    for i in df['Supine Time']:\n",
    "        if i == '- - %':\n",
    "            lst.append('0 minutes 0 %')\n",
    "        else:\n",
    "            lst.append(i)\n",
    "\n",
    "    df['Supine Time'] = lst\n",
    "    saturation_count = df['Supine Time'].str.split(' minutes', n=1).str[0].str.replace(',', '.').astype(float)\n",
    "    saturation_rate = df['Supine Time'].str.split(' minutes', n=1).str[1].str.replace('%', '').str.replace(',', '.').astype(float)\n",
    "    df['Supine Time'] = saturation_rate\n",
    "\n",
    "    #Clean Non-Supine Time Data\n",
    "    lst = []\n",
    "    for i in df['Non-Supine Time']:\n",
    "        if i == '- - %':\n",
    "            lst.append('0 minutes 0 %')\n",
    "        else:\n",
    "            lst.append(i)\n",
    "\n",
    "    df['Non-Supine Time'] = lst\n",
    "    saturation_count = df['Non-Supine Time'].str.split(' minutes', n=1).str[0].str.replace(',', '.').astype(float)\n",
    "    saturation_rate = df['Non-Supine Time'].str.split(' minutes', n=1).str[1].str.replace('%', '').str.replace(',', '.').astype(float)\n",
    "    df['Non-Supine Time'] = saturation_rate\n",
    "\n",
    "    #Clean Upright Time Data\n",
    "    lst = []\n",
    "    for i in df['Upright Time']:\n",
    "        if i == '- - %':\n",
    "            lst.append('0 minutes 0 %')\n",
    "        else:\n",
    "            lst.append(i)\n",
    "\n",
    "    df['Upright Time'] = lst\n",
    "    saturation_count = df['Upright Time'].str.split(' minutes', n=1).str[0].str.replace(',', '.').astype(float)\n",
    "    saturation_rate = df['Upright Time'].str.split(' minutes', n=1).str[1].str.replace('%', '').str.replace(',', '.').astype(float)\n",
    "    df['Upright Time'] = saturation_rate\n",
    "\n",
    "    #Clean Movement Time Data\n",
    "    lst = []\n",
    "    for i in df['Movement Time']:\n",
    "        if i == '- - %':\n",
    "            lst.append('0 minutes 0 %')\n",
    "        else:\n",
    "            lst.append(i)\n",
    "\n",
    "    df['Movement Time'] = lst\n",
    "    saturation_count = df['Movement Time'].str.split(' minutes', n=1).str[0].str.replace(',', '.').astype(float)\n",
    "    saturation_rate = df['Movement Time'].str.split(' minutes', n=1).str[1].str.replace('%', '').str.replace(',', '.').astype(float)\n",
    "    df['Movement Time'] = saturation_rate\n",
    "\n",
    "    #Clean Average Oxygen Saturation Data\n",
    "    df['Average Oxygen Saturation'] = df['Average Oxygen Saturation'].str.replace(' %', '')\n",
    "    df['Average Oxygen Saturation'] = df['Average Oxygen Saturation'].str.replace(',', '.').astype(float)\n",
    "\n",
    "    #Clean Oxygen Desaturation Events Data\n",
    "    apnea_hypopnea_count = df['Oxygen Desaturation Events'].str.split(' ', n=1).str[0].astype(int)\n",
    "    rate = df['Oxygen Desaturation Events'].str.split(' ', n=1).str[1].str.replace(' / h', '')\n",
    "    rate = rate.replace('-', '0')\n",
    "    apnea_hypopnea_rate = rate.str.replace(',', '.').astype(float)\n",
    "    df['Oxygen Desaturation Events'] = apnea_hypopnea_rate\n",
    "\n",
    "    #Clean Autonomic Arousal Data\n",
    "    apnea_hypopnea_count = df['Autonomic Arousal'].str.split(' ', n=1).str[0].astype(int)\n",
    "    rate = df['Autonomic Arousal'].str.split(' ', n=1).str[1].str.replace(' / h', '')\n",
    "    rate = rate.replace('-', '0')\n",
    "    apnea_hypopnea_rate = rate.str.replace(',', '.').astype(float)\n",
    "    df['Autonomic Arousal'] = apnea_hypopnea_rate\n",
    "\n",
    "    #Clean Apenea Table Data\n",
    "    df['apenea'] = df['apenea'].apply(ast.literal_eval)\n",
    "    df_apnea_expanded = pd.concat([json_normalize(record) for record in df['apenea']], ignore_index=True)\n",
    "    apenea_list = []\n",
    "    obstructive_list = []\n",
    "    central_list = []\n",
    "    mixed_list = []\n",
    "    hypopnea_list = []\n",
    "    obstructive_hypopnea_list = []\n",
    "    central_hypopnea_list = []\n",
    "    mixed_hypopnea_list = []\n",
    "\n",
    "    apenea_list1 = []\n",
    "    obstructive_list1 = []\n",
    "    central_list1 = []\n",
    "    mixed_list1 = []\n",
    "    hypopnea_list1 = []\n",
    "    obstructive_hypopnea_list1 = []\n",
    "    central_hypopnea_list1 = []\n",
    "    mixed_hypopnea_list1 = []\n",
    "\n",
    "    lists_number = [\n",
    "        apenea_list,\n",
    "        obstructive_list,\n",
    "        central_list,\n",
    "        mixed_list,\n",
    "        hypopnea_list,\n",
    "        obstructive_hypopnea_list,\n",
    "        central_hypopnea_list,\n",
    "        mixed_hypopnea_list\n",
    "    ]\n",
    "\n",
    "    lists_Mean = [\n",
    "        apenea_list1,\n",
    "        obstructive_list1,\n",
    "        central_list1,\n",
    "        mixed_list1,\n",
    "        hypopnea_list1,\n",
    "        obstructive_hypopnea_list1,\n",
    "        central_hypopnea_list1,\n",
    "        mixed_hypopnea_list1\n",
    "    ]\n",
    "\n",
    "    for i in range(10):\n",
    "        for j, lst in enumerate(lists_number):\n",
    "            if df['apenea'][i][j]['Number'] == '-':\n",
    "                lst.append(0)\n",
    "            else:\n",
    "                lst.append(int(df['apenea'][i][j]['Number']))\n",
    "\n",
    "    for i in range(10):\n",
    "        for j, lst in enumerate(lists_Mean):\n",
    "            if df['apenea'][i][j]['Mean [seconds]'] == '-':\n",
    "                lst.append(0)\n",
    "            else:\n",
    "                value = df['apenea'][i][j]['Mean [seconds]'].replace(',', '.')\n",
    "                lst.append(float(value))\n",
    "\n",
    "    for i in range(8):\n",
    "        name = f\"apenea_{df['apenea'][0][i]['Respiration']}_Number\"\n",
    "        df[name] = lists_number[i]\n",
    "\n",
    "    for i in range(8):\n",
    "        name = f\"apenea_{df['apenea'][0][i]['Respiration']}_Mean [seconds]\"\n",
    "        df[name] = lists_Mean[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise dos Comentários **Polysomnography**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_comments_polysomnography(df):\n",
    "    ner_pipeline = pipeline('ner', model='portugueseNLP/medialbertina_pt-pt_900m_NER', aggregation_strategy='average')\n",
    "    for index, sentence in df['comments'].items():\n",
    "        entities = ner_pipeline(sentence)\n",
    "        with open('../data/csvs/ner_results_Rem.txt', 'a', encoding='utf-8') as file:\n",
    "            # Iterate over the detected entities\n",
    "            file.write(f\"File Index {index}:\\n\")\n",
    "            for entity in entities:\n",
    "                # Extract entity details\n",
    "                entity_text = sentence[entity['start']:entity['end']]\n",
    "                entity_group = entity['entity_group']\n",
    "                # Write the entity details to the file\n",
    "                if entity_group == \"Resultado\":\n",
    "                    continue\n",
    "                file.write(f\"{entity_group} - {entity_text}\\n\")\n",
    "            file.write(\"-------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise dos Comentários **Polygraphy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_comments_polygraphy(df):\n",
    "    ner_pipeline = pipeline('ner', model='portugueseNLP/medialbertina_pt-pt_900m_NER', aggregation_strategy='average')\n",
    "    # Open a file in write mode\n",
    "    with open('../data/csvs/ner_results_Rem_Poly.txt', 'a', encoding='utf-8') as file:\n",
    "        for index, sentence in df['comments'].items():\n",
    "            entities = ner_pipeline(sentence)\n",
    "            # Iterate over the detected entities\n",
    "            file.write(f\"File Index {index}:\\n\")\n",
    "            for entity in entities:\n",
    "                # Extract entity details\n",
    "                entity_text = sentence[entity['start']:entity['end']]\n",
    "                entity_group = entity['entity_group']\n",
    "                # Write the entity details to the file\n",
    "                if entity_group == \"Diagnostico\":\n",
    "                    file.write(f\"{entity_group} - {entity_text}\\n\")\n",
    "                    break\n",
    "            file.write(\"-------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading Polysomnography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'Position': 'Supine', 'Index time': '104,6', 'A or H/h': '29,8'}, {'Position': 'Left', 'Index time': '90,5', 'A or H/h': '2,0'}, {'Position': 'Prone', 'Index time': '0,0', 'A or H/h': '-'}, {'Position': 'Right', 'Index time': '170,4', 'A or H/h': '6,3'}, {'Position': 'Upright', 'Index time': '0,0', 'A or H/h': '-'}, {'Position': 'Unknown', 'Index time': '0,0', 'A or H/h': '-'}]\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/csvs/RemLogicData.csv')\n",
    "df['position'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading Polygraphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/csvs/RemLogicPolyData.csv')\n",
    "clean_common_data(df)\n",
    "clean_data_Polygraphy(df)\n",
    "#analysis_comments_polygraphy(df)\n",
    "df = df.rename(columns={'apenea_Hypopnea (All):_Number': 'apenea_Hypopnea (All)_Number'})\n",
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise do Tempo dos Exames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "univariate_analysis(df, 'total_recording_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise da \"Lowest Oxygen Saturation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "univariate_analysis(df, 'Lowest Oxygen Saturation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise de \"Apnea + Hypopnea (A+H)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "univariate_analysis(df, 'Apnea + Hypopnea (A+H) Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise Bivariável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "numeric_cols_list = list(numeric_cols)\n",
    "numeric_cols_list.remove('ID')\n",
    "numeric_cols = pd.Index(numeric_cols_list)\n",
    "\n",
    "#plot histograms for all numeric columns\n",
    "\"\"\"\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.histplot(df[col])\n",
    "    plt.title(col)\n",
    "    plt.show\n",
    "\"\"\"\n",
    "\n",
    "#plot correlation matrix\n",
    "corr = df[numeric_cols].corr()\n",
    "plt.figure(figsize=(30, 20))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RemLogic Notes\n",
    "Após a análise deste doas conseguimos perceber que o \"total_recording_time\", \"Sleep Efficiency\" e \"Apnea + Hypopnea (A+H)\" não tem qualquer relação entre si, tal como \"Apnea + Hypopnea (A+H)\" e \"Number of Snoring Episodes\". Já o \"Sleep Efficiency\" e \"Apnea + Hypopnea (A+H)\" tal como, \"Lowest Oxygen Saturation\", \"Apnea + Hypopnea (A+H)\" e \"Relative Snoring Time\" tem relações fortes entre si."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/csvs/report_summary.csv')\n",
    "df = df.replace('---', pd.NaT)\n",
    "\n",
    "fix_data_types(df)\n",
    "handle_missing_values(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
